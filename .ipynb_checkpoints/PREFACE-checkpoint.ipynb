{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Computational approaches to neuroscience </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After all, surely a field that is based in the computational sciences should be able to utilize all computational resources to impart knowledge, first of which should be the ability to teach theory with code.\n",
    "\n",
    "\n",
    "### Organization of the book\n",
    "\n",
    "This book is organized for a fresh student of computational neuroscience. As much as possible, this book is organized in a way that first covers abstract or \"simple\" models, and then detail is added to the same model. This is useful in many ways in a book of this form. First, since this is a code-book, the code that is created in previous sections can be reused and built upon. Second, this process of incremental build-up shows both the assumptions made at each step, and the value of adding detail(read variables) to a model. For instance to simulate phenomena that either couldn't be captured with fewer variables, or if variables have biophysical meaning (give examples of each). Third, many times this is chronological and can help understand with history how the field moved forward (XOR problem and multi-layer perceptrons). Last, it helps anchor the previous concepts by applying them immediately. In improvizational theatre, this principle is the basis of creating complex dramatic structures from scratch and is called \"Yes, And\" or \"Accept, and Build\". Soemthing about remedials.\n",
    "\n",
    "### Contributing to this book\n",
    "Lastly, since this is a special kind of book that will be available online, it has been kept modular, i.e. something that can be built upon as a resource, much like a large open source codebase. This implies that we invite book chapters (in the form of Jupyter notebooks) from the community, for topics that could be organized under the umbrella of computational neuroscience, and haven't been covered in this book. Please note that since this is an academic resource, these will only be added to this codebase if the chapter and code is from the authors themselves, from experts in the field, or after a peer-review process. \n",
    "\n",
    "------  Perhaps there can be templates on how book chapters can be organized later: maybe in phase 4 ----------------------------\n",
    "\n",
    "### Acknowledgements\n",
    "The basic structure of the book is based on the lectures and tutorials taken at the Computational Approaches to Memory and Plasticity (CAMP) summer school that takes place at National Centre for Biological Science, Bengaluru, India.\n",
    "\n",
    "This is a jupyter book containing concepts and code for a young student of computational neuroscience to understand in a hands-on way fundamental concepts in the field. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INDEX \n",
    "\n",
    "0. Remedials\n",
    "    1. Introduction to Jupyter notebook and Python\n",
    "    2. Differential equations\n",
    "    3. Dynamical systems\n",
    "        1. Equillibrium points\n",
    "        2. Stability analysis\n",
    "        3. Phase plots\n",
    "        4. Bifurcations\n",
    "        5. Chaos\n",
    "    4. Linear Algebra (?) \n",
    "    5. Simulation basics (Euler's method, integration timesteps, stiff systems, etc.)\n",
    "  \n",
    "1. Neuron as a spherial elephant\n",
    "    1. Integrate and fire (IF neuron)\n",
    "    2. Leaky integrate and fire (LIF neuron)\n",
    "    3. Conductance model\n",
    "    4. Modeling ion channels\n",
    "    5. Abstract Neuron models\n",
    "        1. FHN, Izikevich, etc.\n",
    "\n",
    "2. With 5 parameters, I can make it wiggle its trunk\n",
    "    1. Isopotential neurons - recap\n",
    "    2. Rall's law\n",
    "    3. D-lambda rule\n",
    "    4. Simulating passive neurons with beautiful morphologies\n",
    "        1. Downloading morphology files from various databases.\n",
    "    5. Ion channel distributions\n",
    "        1. Can be split later to its own chapter, for instance, to simulate active dendrites.\n",
    "  \n",
    "3. At the end of the day, it's all chemistry\n",
    "    1. Simulating chemical reaction networks\n",
    "    2. Let's fast forward to the end, shall we? (No dynamics, just the steady states)\n",
    "        1. Bistable systems\n",
    "    3. I like to move it, move it (Dynamics)\n",
    "        1. Bistable systems\n",
    "        2. Oscillators\n",
    "    4. I need some space (diffusion)\n",
    "        1. Turing model\n",
    "    5. How many particles, again? (Stochastic simulation)\n",
    "    6. All in ( Single particle tracking simulations)\n",
    "    7. Multi-compartment models (P2)\n",
    "    8. Hybrid models (P2)\n",
    "    9. Plasticity : BCM Curve (Calcineurin, CamKII)\n",
    "\n",
    "4. Everything is connected (Putting together electrical and chemical dynamics)\n",
    "    1. Downloading morphologies, distribute ion channels, put in spines.\n",
    "    2. Add chemistry and use adapaters to couple the chemistry to electrical dynamics.\n",
    "    3. Wiggly spines (Structural plasticity)\n",
    "    4. Simulating a detailed model\n",
    "    5. Structural plasticity (More stuff to come here, perhaps from CAMP 2019?) (P2)\n",
    "\n",
    "5. Networks\n",
    "    1. Feedforward Networks\n",
    "        1. SynFire Chains\n",
    "        2. Kremkow, Kumar\n",
    "        3. Tim Vogels (P2)\n",
    "    2. Recurrent Networks\n",
    "        1. Brunel, 2000\n",
    "        2. Ostojik, 2014\n",
    "    3. Neural coding\n",
    "    4. Network correlations\n",
    "    5. EI Networks\n",
    "    6. Learning Rules\n",
    "        1. LTP\n",
    "        2. STDP\n",
    "            - Song et al\n",
    "        3. BCM Curve\n",
    "    7. Short Term Plasticity\n",
    "        1. Tsodyks and Markram\n",
    "        2. Band passing network input\n",
    "\n",
    "6. Learning in neuronal networks\n",
    "    1. Perceptron Learning Rule\n",
    "    2. XOR Problem\n",
    "    3. Hopfield Networks (# Could also be in Networks module)\n",
    "    4. Backpropagation\n",
    "        1. Algorithm\n",
    "        2. Problems with biological implementation\n",
    "    5. Spiking neural networks that learn\n",
    "        1. Echo state networks\n",
    "        2. Sophie Deneve's model\n",
    "        3. FORCE\n",
    "        4. FOLLOW\n",
    "    6. Reinforcement Learning\n",
    "  \n",
    "7. Systems and Behavior\n",
    "    1. Rate models\n",
    "    2. Place cell models\n",
    "    3. Neural Coding (Rate and Time codes) (# Currently also in networks module)\n",
    "        1. Golisch and Meister\n",
    "        2. Receptive Fields\n",
    "    4. Sequences and sequence learning (?) (P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": false,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
